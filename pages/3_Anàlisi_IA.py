import streamlit as st
import pandas as pd
import os
import re
from collections import Counter
import requests
from difflib import get_close_matches
import unicodedata

FASTAPI_URL = "http://localhost:8000"   # o la URL donde tengas FastAPI corriendo

def normalize_text_advanced(text):
    """
    Normalitza i neteja el text d'entrada:
    1. Min√∫scules i eliminaci√≥ d'espais.
    2. Eliminaci√≥ d'accents (diacr√≠tics).
    3. Eliminaci√≥ de signes de puntuaci√≥.
    4. Eliminaci√≥ de tipus de via i preposicions comunes.
    """
    if not isinstance(text, str):
        return ""

    text = text.lower().strip()

    # 1. Normalitzaci√≥ d'Unicode (treu accents i diacr√≠tics: 'arag√≥' -> 'arago')
    text = ''.join(c for c in unicodedata.normalize('NFD', text) if unicodedata.category(c) != 'Mn')

    # 2. Neteja de car√†cters i signes
    text = text.replace('.', ' ').replace('-', ' ').replace("'", ' ')
    
    # Llista de tokens de tipus de via i preposicions a ignorar
    tokens_a_ignorar = [
        "carrer", "c", "avinguda", "av", "passeig", "pg", "ronda", "placa", "pl",
        "via", "rambla", "travessera", "ctra",
        "de les", "del", "de la", "de l", "dels", "de", "la", "el", "els", "les", "i"
    ]
    
    # 3. Eliminaci√≥ de tokens
    tokens = []
    for token in text.split():
        if token not in tokens_a_ignorar:
            tokens.append(token)

    return ' '.join(tokens).strip()

# Exemple: 'Prediu la causa per Av. Arag√≥' -> 'prediu causa arago'
# Exemple: 'AVINGUDA DE SARRI√Ä' -> 'sarria'

def predict_calle_via_api(calle: str):
    """Llama al endpoint FastAPI /predict_calle."""
    try:
        resp = requests.post(
            f"{FASTAPI_URL}/predict_calle",
            json={"nombre": calle}
        )
        return resp.json()
    except Exception as e:
        return {"error": f"Error connectant amb el servidor FastAPI: {e}"}


# --- Configuraci√≥ de la P√†gina ---
st.set_page_config(page_title="Analista de Dades d'Accidents", layout="wide")

# üíÖ Estil m√©s "Professional/Anal√≠tic" amb contrast millorat
st.markdown("""
    <style>
    /* Fons clar per an√†lisi */
    [data-testid="stAppViewContainer"] {
        background-color: #f0f2f6; 
    }
    
    /* --- Estil de T√≠tols (Color Rosa Lluent For√ßat) --- */
    .analyst-title {
        font-family: sans-serif;
        text-align: center;
        font-size: 40px;
        color: #FF007F !important; /* TORNA AL ROSA INTENS I LLUENT, FOR√áAT AMB !important */
        text-shadow: 0px 0px 8px rgba(255, 0, 127, 0.7); /* Ombra per simular "lluentor" */
        margin-bottom: 5px;
    }
    .analyst-subtitle {
        text-align: center;
        font-size: 18px;
        color: #333333; /* Gris fosc per a major contrast */
        margin-bottom: 30px;
    }
    
    /* --- Estil per al Chatbot (Bombolla de l'assistent) --- */
    [data-testid="stChatMessageContent"] {
        background-color: #e0f7fa; /* C√≤mic de bombolla clar */
        border-left: 5px solid #00bcd4;
        color: #1a5276; /* TEXT M√âS FOSC per millorar la llegibilitat sobre el fons clar */
        padding: 10px;
        border-radius: 8px;
        font-size: 16px;
    }
    
    /* Estil per a l'entrada de text */
    .stTextInput > div > div > input {
        border-radius: 15px;
        border: 1px solid #00bcd4;
        color: #333;
    }
    
    /* Estil per al text de l'usuari (per defecte de streamlit, per√≤ assegurem contrast) */
    [data-testid="stChatMessage"] .stMarkdown {
        color: #333333; 
    }
    
    </style>
""", unsafe_allow_html=True)

# --- T√≠tol i subt√≠tol ---
st.markdown('<h1 class="analyst-title">ü§ñ Analista de Dades de Tr√†nsit</h1>', unsafe_allow_html=True)
st.markdown('<p class="analyst-subtitle">Fes preguntes concretes sobre els accidents de tr√†nsit a Barcelona basades en les dades que has pujat.</p>', unsafe_allow_html=True)


# --- 1. C√†rrega i Pre-processament de Dades (Funci√≥ de Doble Codificaci√≥) ---
DATA_FOLDER = "data"
os.makedirs(DATA_FOLDER, exist_ok=True)

@st.cache_data
def carregar_csv_desde_carpeta():
    """Carrega tots els CSV amb doble codificaci√≥ (UTF-8 i Latin-1)."""
    arxius = [f for f in os.listdir(DATA_FOLDER) if f.endswith(".csv")]
    dfs = {}
    for arxiu in arxius:
        ruta_arxiu = os.path.join(DATA_FOLDER, arxiu)
        try:
            df = pd.read_csv(ruta_arxiu, sep=',', encoding='utf-8')
            dfs[arxiu] = df
            continue
        except UnicodeDecodeError:
            pass
            
        try:
            df = pd.read_csv(ruta_arxiu, sep=',', encoding='latin-1')
            dfs[arxiu] = df
        except Exception as e:
            st.error(f"‚ùå Error carregant {arxiu}: {e}")
            
    return dfs

# Carregar i combinar les dades
dfs = carregar_csv_desde_carpeta()
if dfs:
    df_accidents = pd.concat(dfs.values(), ignore_index=True)
else:
    df_accidents = pd.DataFrame()


# --- 2. Inicialitzar Historial de Conversa ---
if "messages" not in st.session_state:
    st.session_state.messages = [
        {
            "role": "assistant",
            "content": "S√≥c l'analista de dades. Pots preguntar-me sobre districtes, causes, anys, i tipus d'accidents. Per exemple: 'Quin √©s el districte amb m√©s accidents?' o 'Quina √©s la causa m√©s freq√ºent?'"
        }
    ]

# --- 3. Funci√≥ de L√≤gica de Resposta ---

def detectar_carrer_ontologic(text, df):
    """
    Detecta noms de carrer usant la normalitzaci√≥ avan√ßada i fuzzy matching.
    Ara a√Ølla el nom del carrer del soroll de la pregunta.
    """
    if "Nom_carrer" not in df.columns:
        return None

    # 1. Normalitzem el text de l'usuari (retorna 'prediu causa problable a arago')
    text_normalitzat_complet = normalize_text_advanced(text)

    if not text_normalitzat_complet:
        return None
        
    # NOU PAS CLAU: A√Øllem nom√©s la part final del text (els √∫ltims 4 mots) per a la comparaci√≥ fuzzy.
    text_a_comparar = ' '.join(text_normalitzat_complet.split()[-4:])


    # Obtenim la llista de noms ORIGINALS i NORMALITZATS del dataset
    carrers_originals = df["Nom_carrer"].dropna().unique().tolist()
    # Aquesta llista idealment nom√©s s'hauria de calcular una vegada, fora de la funci√≥.
    carrers_normalitzats = [normalize_text_advanced(c) for c in carrers_originals] 
    
    # 1. Intent de Coincid√®ncia amb les √∫ltimes 4 paraules
    match = get_close_matches(text_a_comparar, carrers_normalitzats, n=1, cutoff=0.7)

    if match:
        # Trobem l'√≠ndex del nom normalitzat que ha coincidit
        index = carrers_normalitzats.index(match[0])
        # Retornem el nom ORIGINAL i correcte del dataset
        return carrers_originals[index]

    # 2. Intent de Coincid√®ncia de paraula √∫nica (per si nom√©s es diu "Diagonal")
    # Si la primera cerca falla, intentem buscar un match nom√©s amb el darrer mot
    if len(text_a_comparar.split()) > 1:
        text_darrer_mot = text_a_comparar.split()[-1]
        
        match_ultim = get_close_matches(text_darrer_mot, carrers_normalitzats, n=1, cutoff=0.7)
        if match_ultim:
            index = carrers_normalitzats.index(match_ultim[0])
            return carrers_originals[index]

    return None


def analitzar_pregunta(user_text, df):
    """Analitza el text de l'usuari i retorna una resposta basada en les dades."""
    if df.empty:
        return "No s'han trobat dades per analitzar. Assegura't de pujar els arxius CSV a la p√†gina '1 Distribuci√≥ Causes'."

    user_text = user_text.lower()
    
    # Estandaritzar noms de columnes per a la l√≤gica d'an√†lisi
    COL_DISTRICTE = 'Nom_districte'
    COL_CAUSA = 'Descripcio_causa_mediata'
    COL_ANY = 'Nk_Any'
    
    resposta = ""
    
    # --- Detecci√≥ de Preguntes Clau ---
    
    # 3.1 Preguntes Generals (Total, Anys)
    if any(keyword in user_text for keyword in ["total accidents", "quants accidents", "nombre total"]):
        total = len(df)
        resposta = f"El nombre total d'accidents registrats a totes les dades combinades √©s de **{total:,}**."

    elif any(keyword in user_text for keyword in ["quants anys", "per√≠ode", "quin rang"]):
        if COL_ANY in df.columns:
            anys = df[COL_ANY].dropna().astype(int).unique()
            if len(anys) > 0:
                min_any, max_any = min(anys), max(anys)
                num_anys = len(anys)
                resposta = f"Les dades cobreixen un total de **{num_anys}** anys, des de **{min_any}** fins a **{max_any}**."
            else:
                resposta = "No s'ha trobat informaci√≥ d'any (columna 'Nk_Any')."
        else:
            resposta = f"No s'ha trobat la columna '{COL_ANY}' per analitzar els anys."
            
    # 3.2 Preguntes sobre Districte
    elif any(keyword in user_text for keyword in ["districte amb m√©s", "districte mes", "districte amb menys"]):
        if COL_DISTRICTE in df.columns:
            # Neteja de dades: Ignorar valors buits o 'Desconegut'
            data = df[df[COL_DISTRICTE].notna() & (df[COL_DISTRICTE].str.strip() != '') & (df[COL_DISTRICTE].str.strip() != 'Desconegut')]
            
            if data.empty:
                resposta = "No hi ha dades de districte v√†lides per a l'an√†lisi."
            else:
                comptatge = data[COL_DISTRICTE].value_counts()
                
                if "menys" in user_text:
                    districte_clau = comptatge.index[-1]
                    total_clau = comptatge.iloc[-1]
                    resposta = f"El districte amb **menys** accidents √©s **{districte_clau}** amb un total de {total_clau:,} accidents."
                else:
                    districte_clau = comptatge.index[0]
                    total_clau = comptatge.iloc[0]
                    resposta = f"El districte amb **m√©s** accidents registrats √©s **{districte_clau}** amb un total de {total_clau:,} accidents."
        else:
            resposta = f"No s'ha trobat la columna '{COL_DISTRICTE}' per analitzar per districte."

 # 3.3 Preguntes sobre Causes
    elif any(keyword in user_text for keyword in ["causa m√©s", "causa mes", "motiu principal", "causes mes frequents"]):
        if COL_CAUSA not in df.columns:
            resposta = f"No s'ha trobat la columna '{COL_CAUSA}' per analitzar les causes."
        else:
            data = df[df[COL_CAUSA].notna() & (df[COL_CAUSA].str.strip() != '')]

        if data.empty:
            resposta = "No hi ha dades de causes v√†lides per a l'an√†lisi."
        else:
            comptatge = data[COL_CAUSA].value_counts().head(3)
            total = len(data)

            linies = []
            for i, (causa, count) in enumerate(comptatge.items(), start=1):
                percentatge = (count / total) * 100
                linies.append(
                    f"**{i}. {causa}** ‚Üí {count:,} casos ({percentatge:.2f}%)"
                )

            resposta = (
                "Les **3 causes mediates m√©s freq√ºents** dels accidents s√≥n:\n\n"
                + "\n".join(linies)
            )
    # 3.4 An√†lisi Espec√≠fica (e.g., Accidents en un any concret)
    elif (any(c in user_text for c in ['accidents', 'casos', 'sinistres']) and 
          re.search(r'\b\d{4}\b', user_text)):
        
        any_trobat = re.search(r'\b\d{4}\b', user_text).group(0)
        
        if COL_ANY in df.columns:
            df_any = df[df[COL_ANY].astype(str) == any_trobat]
            total_any = len(df_any)
            
            if total_any > 0:
                resposta = f"L'any **{any_trobat}** es van registrar **{total_any:,}** accidents. Pots comprovar la distribuci√≥ de causes per a aquest any a la p√†gina 'Distribuci√≥ Causes'."
            else:
                resposta = f"No es van trobar accidents registrats per a l'any **{any_trobat}** en les dades disponibles."
        else:
            resposta = f"No puc filtrar per any perqu√® falta la columna '{COL_ANY}'."
    
    # 3.5 Predicci√≥ IA segons una calle (integraci√≥ FastAPI)
    if any(word in user_text for word in ["prediu", "predicci√≥", "causa probable", "prediccio"]):
        
        # 1) Intent simple amb regex: carrer X
        match = re.search(r"(carrer|avinguda|av\.?|passeig|pg\.?|via|ronda|pla√ßa|travessera)\s+([\w\s\-]+)", user_text)
        
        if match:
            carrer_detectat = match.group(0)
        else:
            # 2) M√®tode robust: fuzzy matching contra tota la llista de carrers
            carrer_detectat = detectar_carrer_ontologic(user_text, df)
        
        if not carrer_detectat:
            return "No he pogut identificar cap carrer a la teva pregunta. Prova amb: 'Prediu la causa probable a Avinguda Diagonal'."

        # Cridar a FastAPI
        result = predict_calle_via_api(carrer_detectat)

        if "error" in result:
            return f"‚ö†Ô∏è Error en la predicci√≥: {result['error']}"

        top_3 = result.get("top_3", [])

        if not top_3:
            return f"No tinc dades suficients per predir a **{carrer_detectat}**."
        
        resposta = (
            f"üîç **Predicci√≥ IA per a _{carrer_detectat}_:**\n\n"
            "Segons el model **Random Forest**, les 3 causes amb m√©s probabilitat s√≥n:\n\n"
        )

        # Iterem sobre el top 3 per crear la llista numerada
        for i, item in enumerate(top_3, 1):
            resposta += f"{i}. **{item['causa']}** ({item['probabilitat']}%)\n"

        return resposta



    # 3.6 Resposta per Defecte
    else:
        # Utilitzar algunes paraules clau per donar una resposta √∫til
        if any(keyword in user_text for keyword in ["hola", "saluda", "bon dia"]):
            resposta = "Hola! Estic preparat per analitzar els accidents de tr√†nsit. Fes-me una pregunta sobre districtes, causes o anys."
        else:
            resposta = "Ho sento, no he ent√®s la teva pregunta. Pots provar amb preguntes m√©s concretes com: 'Quin districte t√© m√©s accidents?' o 'Quina √©s la causa principal?'"
            
    return resposta


# --- 4. Mostrar Missatges i Processar l'Entrada de l'Usuari ---

# Mostrar missatges previs
for msg in st.session_state.messages:
    avatar = "üïµÔ∏è" if msg["role"] == "assistant" else "üë§"
    with st.chat_message(msg["role"], avatar=avatar):
        st.markdown(msg["content"])

# Entrada de l'usuari
if prompt := st.chat_input("Fes la teva pregunta d'an√†lisi aqu√≠..."):
    # Afegir missatge de l'usuari a l'historial
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user", avatar="üë§"):
        st.markdown(prompt)

    # Obtenir la resposta de l'analista
    with st.spinner("Analitzant les dades..."):
        response = analitzar_pregunta(prompt, df_accidents)
        
    # Afegir missatge de l'assistent a l'historial
    st.session_state.messages.append({"role": "assistant", "content": response})

    # Mostrar la resposta de l'assistent
    with st.chat_message("assistant", avatar="üïµÔ∏è"):
        st.markdown(response)

# --- 5. Missatge d'Estat de les Dades ---
if df_accidents.empty:
    st.warning("Estat de les dades: No hi ha dades carregades. Sisplau, puja CSVs a la primera p√†gina.")
else:
    st.sidebar.success(f"Dades carregades correctament: {len(df_accidents):,} registres.")